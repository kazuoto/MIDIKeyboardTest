<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>AudioWorklet Sample Piano-ish</title>
</head>
<body>
  <h1>AudioWorkletでサンプル音源再生にゃ(超簡易版)</h1>
  <button id="startBtn">オーディオ＆MIDI開始にゃ</button>

  <script>
    /* 
      ★★★ 事前に"サンプル音"を1個用意しておくにゃ ★★★
      ここでは「C4のピアノ音」を想定し、
      下記URLから適当にダウンロードした「C4.mp3」を使う例にするにゃ。
      あるいは自分のMP3ファイルをURLに指定してにゃ。

      下は「Salamander Piano」内のC4のURLサンプル例 (ちょっと長い):
      "https://tonejs.github.io/audio/salamander/C4.mp3"
    */
    const SAMPLE_URL = "https://tonejs.github.io/audio/salamander/C4.mp3";

    // ★ AudioWorkletProcessorの実装を文字列で用意する (本来は別ファイルが理想)
    const workletCode = `
      class SamplePlayerProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          // サンプリングデータをFloat32Arrayで保持するにゃ(モノラル前提)
          this.sampleData = null;
          this.sampleRateHost = sampleRate; // ホスト側のサンプルレート
          this.voices = {}; // noteNumberごとに再生ステータスを持つにゃ

          // port.onmessage でメインスレッドからのデータや命令を受け取るにゃ
          this.port.onmessage = (e) => {
            const msg = e.data;
            if (msg.type === "loadSample") {
              // サンプルロード完了データ (Float32Array) を受け取って保存
              this.sampleData = msg.buffer;
            } else if (msg.type === "noteOn") {
              // 再生開始
              const noteNumber = msg.noteNumber;
              // 位置を0にして再生開始するにゃ
              // velocityは一旦無視して一定音量にするか、
              // ここで声ごとにゲイン管理してもOK
              this.voices[noteNumber] = {
                position: 0,
                // サンプル本来のピッチはC4(60) → freq=261.63Hzくらい
                // その周波数比で再生速度を決めるにゃ
                playbackRate: Math.pow(2, (noteNumber - 60) / 12)
              };
            } else if (msg.type === "noteOff") {
              // ボイスを消す(簡易実装で即停止)
              const noteNumber = msg.noteNumber;
              delete this.voices[noteNumber];
            }
          };
        }

        process(inputs, outputs, parameters) {
          const output = outputs[0];
          const channelData = output[0]; // モノラル出力

          if (!this.sampleData) {
            // サンプル未ロードなら全部0クリア
            channelData.fill(0);
            return true;
          }

          // 1サンプルごとに全てのvoiceを合成して書き込むにゃ
          for (let i = 0; i < channelData.length; i++) {
            let out = 0;
            for (let noteNumber in this.voices) {
              const voice = this.voices[noteNumber];
              // voice.position が整数じゃないから、小数部分をfloorしてサンプル参照
              const idx = Math.floor(voice.position);

              // サンプル音が終端を超えたらループしないで止める
              if (idx >= this.sampleData.length) {
                // 止める
                delete this.voices[noteNumber];
                continue;
              }

              // とりあえず線形補間なしで近似値を取る(ガクガク音程だが…)
              const sampleVal = this.sampleData[idx];

              out += sampleVal; // velocityや音量は一旦無視して合計

              // 再生速度に応じてpositionを進める
              voice.position += voice.playbackRate;
            }
            // 出力
            channelData[i] = out * 0.3; // 全体音量ちょい下げ
          }

          return true;
        }
      }

      registerProcessor('sample-player-processor', SamplePlayerProcessor);
    `;

    let audioCtx;
    let sampleNode;
    let sampleGain;

    // サンプルをロードしてFloat32Arrayにする関数
    async function loadSample(url) {
      const res = await fetch(url);
      const arrayBuffer = await res.arrayBuffer();
      // AudioContextでdecodeAudioDataしてステレオ→モノラルに変換してFloat32Arrayへ
      const audioBuf = await audioCtx.decodeAudioData(arrayBuffer);
      // まずはLチャンネルだけ抽出(本当はステレオ合成もやろうと思えばできる)
      const chData = audioBuf.getChannelData(0);
      // そのままFloat32ArrayでOK
      return chData;
    }

    async function startAudioWorklet() {
      // latencyHint: "interactive" でAudioContextを作るにゃ
      audioCtx = new AudioContext({ latencyHint: 'interactive' });
      // AudioWorkletを登録
      await audioCtx.audioWorklet.addModule(
        URL.createObjectURL(new Blob([workletCode], {type: 'application/javascript'}))
      );
      // Node作成
      sampleNode = new AudioWorkletNode(audioCtx, 'sample-player-processor');

      // マスターゲイン
      sampleGain = audioCtx.createGain();
      sampleGain.gain.value = 1.0; // 全音量
      sampleNode.connect(sampleGain).connect(audioCtx.destination);

      // サンプルをロードしてAudioWorkletに送るにゃ
      const sampleData = await loadSample(SAMPLE_URL);
      sampleNode.port.postMessage({
        type: "loadSample",
        buffer: sampleData
      });
    }

    // MIDI処理
    async function startMIDI() {
      const midiAccess = await navigator.requestMIDIAccess();
      for (let input of midiAccess.inputs.values()) {
        input.onmidimessage = (msg) => {
          const [status, data1, data2] = msg.data;
          const command = status & 0xf0;
          if (command === 0x90 && data2 > 0) {
            // NoteOn
            sampleNode.port.postMessage({
              type: "noteOn",
              noteNumber: data1
            });
          } else if (command === 0x80 || (command === 0x90 && data2 === 0)) {
            // NoteOff
            sampleNode.port.postMessage({
              type: "noteOff",
              noteNumber: data1
            });
          }
        };
      }
    }

    document.getElementById('startBtn').addEventListener('click', async () => {
      await startAudioWorklet();
      await audioCtx.resume();
      await startMIDI();
      alert("AudioWorkletサンプラー起動にゃ！キーボード弾いてみてにゃ～🐱");
    });
  </script>
</body>
</html>
