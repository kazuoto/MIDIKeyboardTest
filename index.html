<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Parallel Reverb + Volume Slider + Attack & Release</title>
</head>
<body>
  <h1>並列リバーブ + 音量スライダー + アタック＆リリースにゃ</h1>

  <!-- マスター音量スライダー (0～3倍)。初期値2.0 -->
  <p>
    <label for="volumeSlider">Master Volume:</label>
    <input id="volumeSlider" type="range" min="0" max="3" step="0.01" value="2" />
    <span id="volumeValue">2.00</span>
  </p>

  <!-- ボタン押したらMIDIアクセス＆オーディオ開始 -->
  <button id="startBtn">オーディオ＆MIDI開始にゃ</button>

  <script>
    /*
      ▼ 全体概要
       1) AudioWorkletでマルチサンプル再生
       2) Attack付き (Note On時に少しずつ音量上昇)
       3) Release付き (Note Off時にフェードアウト)
       4) 並列リバーブ (ドライ/ウェット)
       5) マスター音量スライダー (初期2.0、最大3.0)

      ↓ 以下の値を調整すればアタック・リリースを変えられるにゃ
         - attackTime: 0.1 (0.1秒)
         - releaseTime: 1.0 (1秒)
    */

    // リバーブ用IR (自分のGitHubに置いた.wavなど)
    const reverbImpulseURL = "https://kazuoto.github.io/MIDIKeyboardTest/SmallRoom.wav";

    // ピアノサンプル (Salamander Pianoの一部キー)
    const sampleMap = {
      "A0": "A0.mp3","C1": "C1.mp3","Ds1": "Ds1.mp3","Fs1": "Fs1.mp3",
      "A1": "A1.mp3","C2": "C2.mp3","Ds2": "Ds2.mp3","Fs2": "Fs2.mp3",
      "A2": "A2.mp3","C3": "C3.mp3","Ds3": "Ds3.mp3","Fs3": "Fs3.mp3",
      "A3": "A3.mp3","C4": "C4.mp3","Ds4": "Ds4.mp3","Fs4": "Fs4.mp3",
      "A4": "A4.mp3","C5": "C5.mp3","Ds5": "Ds5.mp3","Fs5": "Fs5.mp3",
      "A5": "A5.mp3","C6": "C6.mp3","Ds6": "Ds6.mp3","Fs6": "Fs6.mp3",
      "A6": "A6.mp3","C7": "C7.mp3","Ds7": "Ds7.mp3","Fs7": "Fs7.mp3",
      "A7": "A7.mp3"
    };
    const baseUrl = "https://tonejs.github.io/audio/salamander/";

    /*
      ▼ AudioWorkletコード:
         改良ポイント→ Attack(アタック)とRelease(リリース)を両方実装
    */
    const workletCode = `
      class MultiSampleProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.samples = {};
          this.voices = {};
          this.sampleRateHost = sampleRate; // ブラウザのサンプルレート

          this.port.onmessage = (e) => {
            const msg = e.data;
            if (msg.type === "loadedSamples") {
              this.samples = msg.samples;
            } else if (msg.type === "noteOn") {
              const { noteNumber, velocity, nearestNote } = msg;
              const targetAmp = velocity / 127;

              // ボイス作成にゃ
              this.voices[noteNumber] = {
                position: 0,
                sampleData: this.samples[nearestNote],
                playbackRate: Math.pow(2, (noteNumber - nearestNote) / 12),

                // Attack
                inAttack: true,
                attackTime: 0.1,       // 0.1秒で音量が0→targetAmpへ上がる
                attackStartPos: 0,     // Attack開始時のposition
                attackStartAmp: 0,     // Attack開始時の音量(0)
                targetAmp: targetAmp,  // 攻撃後の最終音量

                // Release
                inRelease: false,
                releaseTime: 1.0,      // 1秒でフェードアウト
                releaseStartPos: 0,
                releaseStartAmp: 0,

                // 現在の振幅(音量)
                amplitude: 0
              };
            } else if (msg.type === "noteOff") {
              // Note Off → リリース開始
              const voice = this.voices[msg.noteNumber];
              if (voice) {
                voice.inRelease = true;
                voice.releaseStartPos = voice.position;
                voice.releaseStartAmp = voice.amplitude; 
              }
            }
          };
        }

        process(inputs, outputs, parameters) {
          const output = outputs[0];
          const channelData = output[0];
          channelData.fill(0);

          if (!this.samples || Object.keys(this.samples).length === 0) {
            return true;
          }

          for (let i = 0; i < channelData.length; i++) {
            let out = 0;

            for (const noteNumber in this.voices) {
              const v = this.voices[noteNumber];
              if (!v.sampleData) continue;

              // 再生位置(少数)
              const idx = v.position;
              const idxInt = Math.floor(idx);
              const idxFrac = idx - idxInt;

              // サンプル終端
              if (idxInt >= v.sampleData.length - 1) {
                delete this.voices[noteNumber];
                continue;
              }

              // 線形補間
              const s1 = v.sampleData[idxInt];
              const s2 = v.sampleData[idxInt + 1] || 0;
              let sampleVal = s1 + (s2 - s1) * idxFrac;

              // アタック処理
              if (v.inAttack) {
                // Attack開始から何フレーム進んだか
                const framesSinceAttack = (v.position - v.attackStartPos) / v.playbackRate;
                const secSinceAttack = framesSinceAttack / this.sampleRateHost;
                if (secSinceAttack >= v.attackTime) {
                  // Attack完了
                  v.inAttack = false;
                  v.amplitude = v.targetAmp;
                } else {
                  // アタック中: 0→targetAmp に線形変化
                  const a = secSinceAttack / v.attackTime;  // 0→1
                  v.amplitude = v.attackStartAmp + (v.targetAmp - v.attackStartAmp)*a;
                }
              }

              // リリース処理
              if (v.inRelease) {
                const framesSinceRelease = (v.position - v.releaseStartPos) / v.playbackRate;
                const secSinceRelease = framesSinceRelease / this.sampleRateHost;
                if (secSinceRelease >= v.releaseTime) {
                  // リリース完了
                  delete this.voices[noteNumber];
                  continue;
                } else {
                  // リリース中: amplitudeを線形に(1→0)へ
                  const r = secSinceRelease / v.releaseTime;
                  const newAmp = v.releaseStartAmp * (1.0 - r);
                  v.amplitude = newAmp;
                }
              }

              // 実際の音量を適用
              sampleVal *= v.amplitude;

              out += sampleVal;

              // 再生位置更新
              v.position += v.playbackRate;
            }

            channelData[i] = out * 0.5;
          }

          return true;
        }
      }

      registerProcessor('multi-sample-processor', MultiSampleProcessor);
    `;

    // グローバル変数
    let audioCtx;
    let sampleNode;  
    let reverbNode;  
    let dryGain;     
    let wetGain;     
    let masterGain;  

    // noteNumber→URLマッピング
    let sampleNoteMap = {};
    let sortedSampleNotes = [];

    // ▼ ボタンクリックで開始
    document.getElementById('startBtn').addEventListener('click', async () => {
      setupSampleMap();
      await startAudioWorklet();
      await audioCtx.resume();
      await loadAndSetReverbImpulse();
      await startMIDI();

      alert("アタック＆リリース付きにゃ！(初期音量2.0 / max3.0)");
    });

    // ▼ AudioWorklet初期化
    async function startAudioWorklet() {
      audioCtx = new AudioContext({ latencyHint: "interactive" });
      // workletコードを登録
      await audioCtx.audioWorklet.addModule(
        URL.createObjectURL(new Blob([workletCode], {type: 'application/javascript'}))
      );

      sampleNode = new AudioWorkletNode(audioCtx, 'multi-sample-processor');
      reverbNode = audioCtx.createConvolver();
      dryGain = audioCtx.createGain();
      wetGain = audioCtx.createGain();
      masterGain = audioCtx.createGain();

      // 並列リバーブ (ドライ/Wet)
      dryGain.gain.value = 1.0;
      wetGain.gain.value = 0.2;
      masterGain.gain.value = 2.0; // 初期音量を2.0に

      // ルーティング
      sampleNode.connect(dryGain).connect(masterGain);
      sampleNode.connect(reverbNode).connect(wetGain).connect(masterGain);
      masterGain.connect(audioCtx.destination);

      // サンプルをロードしてAudioWorkletへ
      const loaded = await loadAllSamples();
      sampleNode.port.postMessage({
        type: "loadedSamples",
        samples: loaded
      });

      setupVolumeSlider();
    }

    // ▼ リバーブIRを読み込む
    async function loadAndSetReverbImpulse() {
      const resp = await fetch(reverbImpulseURL);
      if (!resp.ok) {
        console.error("リバーブIRの取得に失敗にゃ…", resp.status);
        return;
      }
      const arrBuf = await resp.arrayBuffer();
      const audioBuf = await audioCtx.decodeAudioData(arrBuf);
      reverbNode.buffer = audioBuf;
      console.log("リバーブIR読み込み完了にゃ:", reverbNode.buffer);
    }

    // ▼ MIDI
    async function startMIDI() {
      const midiAccess = await navigator.requestMIDIAccess();
      for (let input of midiAccess.inputs.values()) {
        input.onmidimessage = (msg) => {
          const [status, data1, data2] = msg.data;
          const command = status & 0xf0;

          if (command === 0x90 && data2 > 0) {
            noteOn(data1, data2);
          } else if (command === 0x80 || (command === 0x90 && data2 === 0)) {
            noteOff(data1);
          }
        };
      }
    }
    function noteOn(noteNumber, velocity) {
      const nearestSampleNote = findNearestSample(noteNumber);
      sampleNode.port.postMessage({
        type: "noteOn",
        noteNumber,
        velocity,
        nearestNote: nearestSampleNote
      });
    }
    function noteOff(noteNumber) {
      sampleNode.port.postMessage({
        type: "noteOff",
        noteNumber
      });
    }

    // ▼ サンプルをロード (各noteNumber→Float32Array)
    async function loadAllSamples() {
      const samples = {};
      const noteNumbers = Object.keys(sampleNoteMap).map(n => parseInt(n));
      for (let nn of noteNumbers) {
        const url = sampleNoteMap[nn];
        const resp = await fetch(url);
        const buf = await resp.arrayBuffer();
        const audioBuf = await audioCtx.decodeAudioData(buf);
        const chData = audioBuf.getChannelData(0);
        samples[nn] = chData;
      }
      return samples;
    }

    // ▼ sampleMap → noteNumber
    function setupSampleMap() {
      for (let key in sampleMap) {
        const nn = noteNameToMidi(key);
        sampleNoteMap[nn] = baseUrl + sampleMap[key];
      }
      sortedSampleNotes = Object.keys(sampleNoteMap)
                                .map(n => parseInt(n))
                                .sort((a,b)=>a-b);
    }
    function findNearestSample(midiNote) {
      let nearest = sortedSampleNotes[0];
      let minDist = Infinity;
      for (const sn of sortedSampleNotes) {
        const dist = Math.abs(sn - midiNote);
        if (dist < minDist) {
          minDist = dist;
          nearest = sn;
        }
      }
      return nearest;
    }

    // "A4" -> 69 など
    function noteNameToMidi(noteName) {
      const table = {
        "C":0,"C#":1,"Db":1,"D":2,"D#":3,"Eb":3,"E":4,"F":5,"F#":6,"Gb":6,
        "G":7,"G#":8,"Ab":8,"A":9,"A#":10,"Bb":10,"B":11
      };
      let m = noteName.match(/^([A-G][#s]?)(\\d+)/);
      if (!m) m = noteName.match(/^([A-G][#s]?)(\d+)/); // 修正: ¥ じゃなく \
      if (!m) return 60;
      let noteStr = m[1].replace("s","#");
      let octave = parseInt(m[2],10);
      let semitone = table[noteStr] ?? 0;
      return semitone + (octave + 1)*12;
    }

    // ▼ マスター音量スライダー (0→3, 初期2)
    function setupVolumeSlider() {
      const slider = document.getElementById('volumeSlider');
      const label = document.getElementById('volumeValue');

      let val = parseFloat(slider.value);
      label.textContent = val.toFixed(2);

      slider.addEventListener('input', () => {
        const val = parseFloat(slider.value);
        if (masterGain) {
          masterGain.gain.value = val;
        }
        label.textContent = val.toFixed(2);
      });
    }
  </script>
</body>
</html>
