<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Poly Voices + Attack & Release + Parallel Reverb + Volume Slider</title>
</head>
<body>
  <h1>同じノート連打OKな複数ボイス版 + アタック&リリース + リバーブ + 音量スライダーにゃ</h1>

  <!-- マスター音量スライダー (0～3倍)。初期値2.0 -->
  <p>
    <label for="volumeSlider">Master Volume:</label>
    <input id="volumeSlider" type="range" min="0" max="3" step="0.01" value="2" />
    <span id="volumeValue">2.00</span>
  </p>

  <button id="startBtn">オーディオ＆MIDI開始にゃ</button>

  <script>
    /*
      ▼ 変更点のポイント
       1) this.voices を「配列」に変更
       2) Note Onのたびに新しいボイスオブジェクトを push() する
       3) Note Off時は「一番最近作られた同じnoteNumberのボイス」を探して inRelease にする
          (前のボイスがまだ鳴ってても上書きしない)
       4) これで同じノート連打しても前の音がぶつ切りされず自然な重なりが得られるにゃ
    */

    // リバーブ用IR (好きなファイルに書き換え可)
    const reverbImpulseURL = "https://kazuoto.github.io/MIDIKeyboardTest/SmallRoom.wav";

    // Salamander Piano の一部キー
    const sampleMap = {
      "A0": "A0.mp3","C1": "C1.mp3","Ds1": "Ds1.mp3","Fs1": "Fs1.mp3",
      "A1": "A1.mp3","C2": "C2.mp3","Ds2": "Ds2.mp3","Fs2": "Fs2.mp3",
      "A2": "A2.mp3","C3": "C3.mp3","Ds3": "Ds3.mp3","Fs3": "Fs3.mp3",
      "A3": "A3.mp3","C4": "C4.mp3","Ds4": "Ds4.mp3","Fs4": "Fs4.mp3",
      "A4": "A4.mp3","C5": "C5.mp3","Ds5": "Ds5.mp3","Fs5": "Fs5.mp3",
      "A5": "A5.mp3","C6": "C6.mp3","Ds6": "Ds6.mp3","Fs6": "Fs6.mp3",
      "A6": "A6.mp3","C7": "C7.mp3","Ds7": "Ds7.mp3","Fs7": "Fs7.mp3",
      "A7": "A7.mp3"
    };
    const baseUrl = "https://tonejs.github.io/audio/salamander/";

    /*
      ▼ AudioWorkletコード (複数ボイス管理+Attack&Release)
         - this.voices は配列
         - noteOnで push
         - noteOffで該当ボイスを検索
    */
    const workletCode = `
      class MultiSampleProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.samples = {};
          // ★ 配列で複数ボイス管理
          this.voices = [];
          this.sampleRateHost = sampleRate;

          this.port.onmessage = (e) => {
            const msg = e.data;
            if (msg.type === "loadedSamples") {
              this.samples = msg.samples;
            } else if (msg.type === "noteOn") {
              const { noteNumber, velocity, nearestNote } = msg;
              const targetAmp = velocity / 127;

              // 新しいボイスオブジェクトをpush
              this.voices.push({
                noteNumber: noteNumber,
                position: 0,
                sampleData: this.samples[nearestNote] || null,
                playbackRate: Math.pow(2, (noteNumber - nearestNote) / 12),

                // Attack
                inAttack: true,
                attackTime: 0.1,  // 0.1秒
                attackStartPos: 0,
                attackStartAmp: 0,
                targetAmp: targetAmp,

                // Release
                inRelease: false,
                releaseTime: 1.0,
                releaseStartPos: 0,
                releaseStartAmp: 0,

                // 現在の振幅
                amplitude: 0
              });
            } else if (msg.type === "noteOff") {
              const noteNum = msg.noteNumber;
              // 一番最近作られた「noteNumと一致、まだリリース入ってない」ボイスを探す
              for (let i = this.voices.length - 1; i >= 0; i--) {
                const v = this.voices[i];
                if (v.noteNumber === noteNum && !v.inRelease) {
                  // リリース開始
                  v.inRelease = true;
                  v.releaseStartPos = v.position;
                  v.releaseStartAmp = v.amplitude;
                  break; // 一つだけリリースすればOK
                }
              }
            }
          };
        }

        process(inputs, outputs, parameters) {
          const output = outputs[0];
          const channelData = output[0];
          channelData.fill(0);

          if (!this.samples || Object.keys(this.samples).length === 0) {
            return true;
          }

          for (let i = 0; i < channelData.length; i++) {
            let out = 0;

            // 配列の全ボイスを合成
            for (let vIndex = 0; vIndex < this.voices.length; vIndex++) {
              const v = this.voices[vIndex];
              if (!v.sampleData) continue;

              const idx = v.position;
              const idxInt = Math.floor(idx);
              const idxFrac = idx - idxInt;

              // サンプル終端
              if (idxInt >= v.sampleData.length - 1) {
                // ボイス削除: splice
                this.voices.splice(vIndex, 1);
                vIndex--;
                continue;
              }

              // 線形補間
              const s1 = v.sampleData[idxInt];
              const s2 = v.sampleData[idxInt + 1] || 0;
              let sampleVal = s1 + (s2 - s1) * idxFrac;

              // Attack処理
              if (v.inAttack) {
                const framesSinceAttack = (v.position - v.attackStartPos) / v.playbackRate;
                const secSinceAttack = framesSinceAttack / this.sampleRateHost;
                if (secSinceAttack >= v.attackTime) {
                  // Attack完了
                  v.inAttack = false;
                  v.amplitude = v.targetAmp;
                } else {
                  const a = secSinceAttack / v.attackTime;
                  v.amplitude = v.attackStartAmp + (v.targetAmp - v.attackStartAmp)*a;
                }
              }

              // リリース処理
              if (v.inRelease) {
                const framesSinceRelease = (v.position - v.releaseStartPos) / v.playbackRate;
                const secSinceRelease = framesSinceRelease / this.sampleRateHost;
                if (secSinceRelease >= v.releaseTime) {
                  // リリース完了→ボイス削除
                  this.voices.splice(vIndex, 1);
                  vIndex--;
                  continue;
                } else {
                  const r = secSinceRelease / v.releaseTime;
                  v.amplitude = v.releaseStartAmp * (1.0 - r);
                }
              }

              // 音量適用
              sampleVal *= v.amplitude;

              out += sampleVal;

              // 再生位置を進める
              v.position += v.playbackRate;
            }

            channelData[i] = out * 0.5;
          }

          return true;
        }
      }

      registerProcessor('multi-sample-processor', MultiSampleProcessor);
    `;

    // グローバル変数
    let audioCtx;
    let sampleNode;  
    let reverbNode;  
    let dryGain;     
    let wetGain;     
    let masterGain;  

    let sampleNoteMap = {};
    let sortedSampleNotes = [];

    // ▼ 起動
    document.getElementById('startBtn').addEventListener('click', async () => {
      setupSampleMap();
      await startAudioWorklet();
      await audioCtx.resume();
      await loadAndSetReverbImpulse();
      await startMIDI();

      alert("同じノート連打OK! Attack & Release付き + リバーブ + スライダーにゃ");
    });

    // ▼ AudioWorklet初期化
    async function startAudioWorklet() {
      audioCtx = new AudioContext({ latencyHint: "interactive" });
      await audioCtx.audioWorklet.addModule(
        URL.createObjectURL(new Blob([workletCode], {type: 'application/javascript'}))
      );

      sampleNode = new AudioWorkletNode(audioCtx, 'multi-sample-processor');
      reverbNode = audioCtx.createConvolver();
      dryGain = audioCtx.createGain();
      wetGain = audioCtx.createGain();
      masterGain = audioCtx.createGain();

      // 並列リバーブ
      dryGain.gain.value = 1.0;
      wetGain.gain.value = 0.2;
      masterGain.gain.value = 2.0; // 初期音量2.0

      // パラレルルーティング
      sampleNode.connect(dryGain).connect(masterGain);
      sampleNode.connect(reverbNode).connect(wetGain).connect(masterGain);
      masterGain.connect(audioCtx.destination);

      // サンプルロード
      const loaded = await loadAllSamples();
      sampleNode.port.postMessage({
        type: "loadedSamples",
        samples: loaded
      });

      // スライダー
      setupVolumeSlider();
    }

    // ▼ リバーブ
    async function loadAndSetReverbImpulse() {
      const resp = await fetch(reverbImpulseURL);
      if (!resp.ok) {
        console.error("リバーブIRの取得に失敗にゃ…", resp.status);
        return;
      }
      const arrBuf = await resp.arrayBuffer();
      const audioBuf = await audioCtx.decodeAudioData(arrBuf);
      reverbNode.buffer = audioBuf;
      console.log("リバーブIR読み込み完了にゃ:", reverbNode.buffer);
    }

    // ▼ MIDI
    async function startMIDI() {
      const midiAccess = await navigator.requestMIDIAccess();
      for (let input of midiAccess.inputs.values()) {
        input.onmidimessage = (msg) => {
          const [status, data1, data2] = msg.data;
          const command = status & 0xf0;

          if (command === 0x90 && data2 > 0) {
            noteOn(data1, data2);
          } else if (command === 0x80 || (command === 0x90 && data2 === 0)) {
            noteOff(data1);
          }
        };
      }
    }
    function noteOn(noteNumber, velocity) {
      const nearestSampleNote = findNearestSample(noteNumber);
      sampleNode.port.postMessage({
        type: "noteOn",
        noteNumber,
        velocity,
        nearestNote: nearestSampleNote
      });
    }
    function noteOff(noteNumber) {
      sampleNode.port.postMessage({
        type: "noteOff",
        noteNumber
      });
    }

    // ▼ サンプルロード
    async function loadAllSamples() {
      const samples = {};
      const noteNumbers = Object.keys(sampleNoteMap).map(n => parseInt(n));
      for (let nn of noteNumbers) {
        const url = sampleNoteMap[nn];
        const resp = await fetch(url);
        const buf = await resp.arrayBuffer();
        const audioBuf = await audioCtx.decodeAudioData(buf);
        const chData = audioBuf.getChannelData(0);
        samples[nn] = chData;
      }
      return samples;
    }

    // ▼ sampleMap → noteNumber
    function setupSampleMap() {
      for (let key in sampleMap) {
        const nn = noteNameToMidi(key);
        sampleNoteMap[nn] = baseUrl + sampleMap[key];
      }
      sortedSampleNotes = Object.keys(sampleNoteMap)
                                .map(n => parseInt(n))
                                .sort((a,b)=>a-b);
    }
    function findNearestSample(midiNote) {
      let nearest = sortedSampleNotes[0];
      let minDist = Infinity;
      for (const sn of sortedSampleNotes) {
        const dist = Math.abs(sn - midiNote);
        if (dist < minDist) {
          minDist = dist;
          nearest = sn;
        }
      }
      return nearest;
    }
    // ノート名→ノート番号
    function noteNameToMidi(noteName) {
      const table = {
        "C":0,"C#":1,"Db":1,"D":2,"D#":3,"Eb":3,"E":4,"F":5,"F#":6,"Gb":6,
        "G":7,"G#":8,"Ab":8,"A":9,"A#":10,"Bb":10,"B":11
      };
      let m = noteName.match(/^([A-G][#s]?)(\d+)/);
      if (!m) return 60;
      let noteStr = m[1].replace("s","#");
      let octave = parseInt(m[2],10);
      let semitone = table[noteStr] ?? 0;
      return semitone + (octave + 1)*12;
    }

    // ▼ マスター音量スライダー
    function setupVolumeSlider() {
      const slider = document.getElementById('volumeSlider');
      const label = document.getElementById('volumeValue');

      let val = parseFloat(slider.value);
      label.textContent = val.toFixed(2);

      slider.addEventListener('input', () => {
        const val = parseFloat(slider.value);
        if (masterGain) {
          masterGain.gain.value = val;
        }
        label.textContent = val.toFixed(2);
      });
    }
  </script>
</body>
</html>
